From 79e28897450b771368b8ca3c64dc60c3287aa262 Mon Sep 17 00:00:00 2001
From: Bryan Cantrill <bryan@joyent.com>
Date: Thu, 7 Jun 2018 14:18:29 -0700
Subject: [PATCH] joyent/manta-thoth#151 "thoth init" should be documented
 joyent/manta-thoth#158 document "limit=" dump specifier
 joyent/manta-thoth#159 document "mtime=" dump specifier
 joyent/manta-thoth#160 add dump specifier for dump IDs via stdin
 joyent/manta-thoth#161 "thoth upload" should update database
 joyent/manta-thoth#162 allow mdb commands to be run via "thoth analyze"

---
 README.md    | 221 ++++++++++++++++++++++++++++++++++++++++++---------
 bin/thoth    | 127 +++++++++++++++++++++++++----
 package.json |   2 +-
 3 files changed, 295 insertions(+), 55 deletions(-)

diff --git a/README.md b/README.md
index 1e17a99..2d08cc2 100644
--- a/README.md
+++ b/README.md
@@ -14,8 +14,8 @@ further data movement.
 
 # Setup
 
-As with the [node-manta](https://github.com/joyent/node-manta) CLI tools, you will
-need to set Manta environment variables that match your Joyent Manta account:
+As with the [node-manta](https://github.com/joyent/node-manta) CLI tools,
+you will need to set Manta environment variables that match your Manta account:
 
     $ export MANTA_KEY_ID=`ssh-keygen -l -f ~/.ssh/id_rsa.pub | awk '{print $2}' | tr -d '\n'`
     $ export MANTA_URL=https://us-east.manta.joyent.com
@@ -27,40 +27,173 @@ uses the 'thoth' Manta user:
 
     $ export THOTH_USER=thoth
 
+If `$THOTH_USER` is set, `$MANTA_USER` must have read and write access
+to `/$THOTH_USER/stor/thoth`.
+
+While all of its canonical data resides in Manta, Thoth uses
+[RethinkDB](https://www.rethinkdb.com) for metadata caching.
+If setting up  a new `$THOTH_USER`,
+[RethinkDB should be installed](https://www.rethinkdb.com/docs/install/)
+separately, and then pointed to via `$THOTH_USER/stor/thoth/config.json`
+as described below.
+
+Once RethinkDB is installed, the `authKey` should be set.
+On versions of RethinkDB of 2.3 or more recent, this can be done via the
+Data Explorer from the RethinkDB web interface:
+
+    r.db('rethinkdb').table('users').get('admin').update({password:'I<3dumps!'})
+
+(Once this has been done, it's wise to disable web administration by
+uncommenting the `no-http-admin` line in the RethinkDB instances's configuration file.)
+
+To initialize thoth, first store the RethinkDB credentials in Manta at
+`$THOTH_USER/stor/thoth/config.json`:
+
+    {
+            "db": { "host": "my-thoth-server", "authKey": "I<3dumps!" }
+    }
+
+Then, run `thoth init`:
+
+    $ thoth init
+    thoth: using database at my-thoth-server:28015 (configured from Manta)
+    thoth: created database 'bcantrill'
+    thoth: created table 'dumps'
+    thoth: created table 'analyzers'
+    thoth: created index 'time'
+
+Now you can upload your first core dump:
+
+    $ thoth upload ./core.bc.24388
+    thoth: using database at my-thoth-server:28015 (configured from Manta)
+    thoth: creating 76998f82a450a8914037e4da838ec609
+    thoth: uploading core.bc.24388 to 76998f82a450a8914037e4da838ec609
+    thoth: core.bc.24388 [=======================>] 100%   3.83MB 
+    thoth: creating job to uncompress 76998f82a450a8914037e4da838ec609
+    thoth: adding key to job 42b9feff-56d5-482a-b12b-da2099fd44ed
+    thoth: processing job 42b9feff-56d5-482a-b12b-da2099fd44ed
+    thoth: waiting for completion of job 42b9feff-56d5-482a-b12b-da2099fd44ed
+    thoth: job 42b9feff-56d5-482a-b12b-da2099fd44ed completed in 0h0m14s
+    thoth: creating job to process 76998f82a450a8914037e4da838ec609
+    thoth: adding key to job 3e434caf-0544-6e89-ed71-8fa1630adcde
+    thoth: processing 76998f82a450a8914037e4da838ec609
+    thoth: waiting for completion of job 3e434caf-0544-6e89-ed71-8fa1630adcde
+    thoth: job 3e434caf-0544-6e89-ed71-8fa1630adcde completed in 0h0m8s
+
+This dump should appear in `thoth ls` output:
+
+    $ thoth ls
+    thoth: using database at my-thoth-server:28015 (configured from Manta)
+    NAME             TYPE  TIME                NODE/CMD         TICKET  
+    76998f82a450a891 core  2015-12-04T13:10:26 bc               -       
+
 # Running Thoth
 
 ## Introduction
 
 Thoth consists primarily of the `thoth` utility, a veneer on Manta that
-generates a _hash_ unique to a core or crash dump, uploads that
-dump to a directory under `$MANTA_USER/stor/thoth`, and offers
-facilities to list, filter and (most importantly) debug those dumps
-in place.  Most `thoth` subcommands operate on a _dump specification_:
-a dump's hash (or substring thereof) or a space-delimited set of
-constraints based on its properties.  A constraint consists of
-a property name, a single equals sign, and the value (or globbed expression)
-to match.  For example, to list all crash dumps from the node  95SY9R1
+generates a _hash_ unique to a core or crash dump, uploads that dump to a
+directory under `$MANTA_USER/stor/thoth`, loads the metadata associated
+with the dump into a RethinkDB-based querying database, and offers facilities
+to list, filter and (most importantly) debug those dumps in place.
+
+### Dump specifications
+
+Most `thoth` subcommands operate on a _dump specification_: a dump's hash
+(or substring thereof) or a space-delimited set of constraints based on its
+properties.  A constraint consists of a property name, a single equals sign,
+and the value (or globbed expression) to match.  For example, to list all
+crash dumps from the node 95SY9R1:
 
     $ thoth ls type=crash node=95SY9R1
 
-The special token `undefined` denotes a property that isn't set.
-For example, to list all dumps that begin with `svc` that don't have a ticket:
-
-    $ thoth ls cmd=svc* ticket=undefined
-    thoth: creating job to list
-    thoth: created job 3f5f8e94-6fbe-400b-b7d5-a666a2012066
-    thoth: waiting for completion of job 3f5f8e94-6fbe-400b-b7d5-a666a2012066
-    thoth: job 3f5f8e94-6fbe-400b-b7d5-a666a2012066 completed in 0h0m26s
-    DUMP             TYPE  TIME                NODE/CMD         TICKET
-    8eaa35bb82c20716 core  2013-06-26T17:01:29 svc.startd       -
-    06880c6f00a2ab47 core  2013-06-26T18:04:56 svc.startd       -
-    8df0e4e9d9a67581 core  2013-06-26T18:04:57 svc.startd       -
-    9a1ec403c6e78b95 core  2013-06-26T19:04:24 svc.startd       -
-    ddaca0c9fbae4ff6 core  2013-06-26T19:23:41 svc.startd       -
-    b791a00a788c9d59 core  2013-06-27T01:26:05 svc.configd      -
-    3dae4877554defc4 core  2013-07-06T07:02:38 svc.configd      -
-    7866184c07c23510 core  2013-07-11T04:47:56 svc.startd       -
-    e407e3820d3af9ab core  2013-07-11T04:47:56 svc.startd       -
+#### Special token: `mtime`
+
+The special token `mtime` denotes how long ago the dump was uploaded,
+with equality denoting recency.  For example, to list all of the dumps
+uploaded in the last 6 hours:
+
+    $ thoth ls mtime=6h 
+    thoth: using database at thoth-db:28015 (configured from Manta)
+    NAME             TYPE  TIME                NODE/CMD         TICKET
+    e1f5422b892d9394 core  2017-11-17T19:34:29 java             -     
+    c04110bc8190a84e core  2017-11-17T19:39:52 node             -     
+    b9379570b4a9a224 core  2017-11-17T19:39:52 node             -     
+    5f1171019ce419cb core  2017-11-17T19:51:01 node             -     
+    713f9e8b48559acd core  2017-11-17T19:55:57 node             -     
+    d91719939666de40 core  2017-11-17T20:05:57 node             -     
+    beaa65d3548ac96f core  2017-11-17T20:23:19 pg_prefaulter    -     
+    5841ba86a2b198be core  2017-11-17T20:53:06 node             -     
+    3d8921ce583dff68 core  2017-11-17T20:54:06 node             -     
+    34a8661c049456b1 core  2017-11-17T21:14:09 node             -     
+    6d75f1cd30898f48 core  2017-11-17T21:31:19 node             -     
+    cc2328f7d8a6c4ad core  2017-11-17T21:41:15 node             -     
+    b0b6f4ed9ab418ce core  2017-11-17T21:51:20 node             -     
+    5d64e695505d15c9 core  2017-11-17T22:11:18 node             -     
+    96d2271d81e4cd63 core  2017-11-17T22:21:17 node             -     
+    71aff9c315553b03 core  2017-11-17T23:31:14 node             -     
+    72f18495c7f54841 core  2017-11-18T00:21:17 node             -     
+
+#### Special token: `limit`
+
+The special token `limit` denotes that the number of dumps specified
+should be limited to the parameter, allowing a smaller number of 
+dumps to be examined.  (Exactly which dumps will be returned is unspecified.)
+For example, to get the ID of at most five dumps from commands that begin with
+"system":
+
+    $ thoth info cmd=systemd* limit=5 | json -ga id
+    thoth: using database at thoth-db:28015 (configured from Manta)
+    00103a107b5db8f79ebc77782b707d07
+    0071f6c50b39f1a917ba21a957f43e3f
+    0021e9c447815c1f7a91e1af2672543b
+    00d7ae803e01365798654c4dbeea5b28
+    012c3f942d0b7de6b7dbc8eed8798b86
+
+#### Special token: `undefined`
+
+The special token `undefined` denotes a property that isn't set.  For
+example, to list all dumps that were added in the last one hundred days that
+begin with `svc` that don't have a ticket:
+
+    $ thoth ls mtime=100d cmd=svc* ticket=undefined
+    thoth: using database at thoth-db:28015 (configured from Manta)
+    NAME             TYPE  TIME                NODE/CMD         TICKET
+    0ecc8338c5949ea7 core  2017-08-10T01:57:56 svc.startd       -     
+    925de938d529e58b core  2017-08-18T03:51:27 svcs             -     
+    1d16db174473d8b5 core  2017-08-18T04:53:30 svcs             -     
+    2b4b3f5931e4b945 core  2017-08-18T05:39:14 svcs             -     
+    c5761bf75ea51a3f core  2017-08-18T08:27:01 svcs             -     
+    2204949c1735126b core  2017-08-18T15:08:35 svcs             -     
+    bc987a441a10da48 core  2017-08-24T17:44:41 svc.startd       -     
+    d7ba3510178394c3 core  2017-09-06T12:53:45 svcs             -     
+    48157650dc2d4204 core  2017-09-07T00:24:59 svccfg           -     
+    c48278b2930f991c core  2017-09-07T01:09:49 svccfg           -     
+    14918d63fb7239da core  2017-09-26T01:26:44 svc.startd       -     
+    9a29ead38c89930a core  2017-10-01T08:22:37 svc.configd      -     
+    d36a11c974f7f03d core  2017-10-01T08:22:37 svc.startd       -     
+    463412ce271ec7ec core  2017-10-02T15:39:23 svc.startd       -     
+
+#### Special specification: `dump=stdin`
+
+The special specification `dump=stdin` denotes that dump identifiers should
+be read from standard input, e.g.:
+
+    $ cat /tmp/dumps
+    3f7a8bde5a907afab7f966b9963c7d10
+    3260a5e49918260ccdc1f94830c937c1
+    f12ea8712e8b2586f062b03808b1c292
+    5aaa91149e94a91f66c76b00ec1de521
+    04a681f27ffcd19952d8efb75006c490
+    $ cat /tmp/dumps | thoth ls dump=stdin
+    thoth: using database at thoth-db:28015 (configured from Manta)
+    thoth: reading dump identifiers from stdin
+    NAME             TYPE  TIME                NODE/CMD         TICKET
+    3260a5e49918260c core  2017-11-16T22:30:22 pg_prefaulter    -     
+    5aaa91149e94a91f core  2017-11-17T11:07:43 pg_prefaulter    -     
+    04a681f27ffcd199 core  2017-11-17T14:12:27 pg_prefaulter    -     
+    3f7a8bde5a907afa core  2017-11-17T14:42:03 pg_prefaulter    -     
+    f12ea8712e8b2586 core  2017-11-17T17:22:21 pg_prefaulter    -     
 
 ## Subcommands
 
@@ -165,9 +298,15 @@ via [mlogin](http://blog.sysmgr.org/2013/06/manta-mlogin.html).
 ### ls
 
 Lists the dumps that match the dump specification, or all dumps if no
-dump specification is provided.  A dump abbreviation, the dump type, the
-time, the node or command, and the ticket are provided for each dump.
-By default, the dumps are listed in time order from oldest to newest.
+dump specification is provided.  By default, the dumps are listed in time
+order from oldest to newest.
+
+A dump abbreviation, the dump type, the time, the node or command, and the
+ticket are provided for each dump -- but `ls` will additionally display
+any property provided.  For example, to list the stack trace in addition for
+all dumps in the last three days from the `pg_prefaulter` command:
+
+    $ thoth ls mtime=3d cmd=pg_prefaulter stack
 
 ### object
 
@@ -354,18 +493,18 @@ Manta paths that may be retrieved with mget.
     /thoth/stor/thoth/analyzers/OS-2359-stacks
     /thoth/stor/thoth/analyzers/fmri
 
-# Thoth and SmartDataCenter
+# Thoth and Triton 
 
-For users of Joyent's SmartDataCanter, `sdc-thoth` allows for Thoth to
-be integrated and run on a regular basis from the head-node.  `sdc-thoth`
-operates by querying compute nodes for dumps and their
-corresponding hashes, checking those hashes against Thoth, and uploading
-any missing dumps through the head-node and into Thoth.
+For users of Joyent's Triton (nÃ©e SmartDataCenter), `sdc-thoth` allows for
+Thoth to be integrated and run on a regular basis from the headnode.
+`sdc-thoth` operates by querying compute nodes for dumps and their
+corresponding hashes, checking those hashes against Thoth, and uploading any
+missing dumps through the headnode and into Thoth.
 
 ## Installation
 
-Running `sdc-thoth-install` as root on the head-node will install the
-latest binary on the head-node in `/opt/custom`, create a `thoth`
+Running `sdc-thoth-install` as root on the headnode will install the
+latest binary on the headnode in `/opt/custom`, create a `thoth`
 user and create the necessary SMF manifest as well as a `crontab` that
 runs `sdc-thoth` in dry-run mode.  You can also download and execute
 this directly from Manta (with the obvious caveats that you should really
@@ -374,6 +513,10 @@ as `root`):
 
     # curl -k https://us-east.manta.joyent.com/thoth/public/sdc-thoth-install | bash
 
+Before running `sdc-thoth-install`, you will need to login to the
+headnode with the credentials to add an SSH key to the account that is 
+to be used for Thoth.
+
 ## License
 
 The MIT License (MIT)
diff --git a/bin/thoth b/bin/thoth
index 3e3e5cc..8dea1a6 100755
--- a/bin/thoth
+++ b/bin/thoth
@@ -947,12 +947,76 @@ jobExecThoth = function (what)
 	    'load ' + what);
 }
 
-dumpsFromSpec = function (argv, opts, cb)
+dumpsFromStdin = function (client, opts, cb)
+{
+	process.stdin.resume();
+	process.stdin.setEncoding('utf8');
+
+	var lines;
+	var lingeringLine = '';
+	var dumps = [];
+
+	var processLine = function (l) { if (l.length > 0) dumps.push(l); };
+
+	if (!client)
+		client = connect();
+
+	status('reading dump identifiers from stdin');
+
+	process.stdin.on('data', function (chunk) {
+		lines = chunk.split(/\s+/);
+
+		lines[0] = lingeringLine + lines[0];
+		lingeringLine = lines.pop();
+
+		lines.forEach(processLine);
+	});
+
+	process.stdin.on('end', function () {
+		var all = [];
+
+		processLine(lingeringLine);
+
+		if (dumps.length == 0)
+			fatal('"stdin" specified, but no dumps provided');
+
+		dumps.forEach(function (dump) {
+			infoGet(client, dump, function (info) {
+				all.push(info);
+
+				if (all.length == dumps.length)
+					cb(all);
+			}, true);
+		});
+	});
+}
+
+dumpsFromSpec = function (client, argv, opts, cb)
 {
 	var i;
 	var illegal = undefined;
 	var filters = [], time = undefined, undefs = [], limit = undefined;
 
+	/*
+	 * This is a little isntall-ish, but we allow several different ways
+	 * of specifying that dump UUIDs should be read from stdin.
+	 */
+	if (argv[0] == 'dump=stdin' || argv[0] == 'dumps=stdin' ||
+	    argv[0] == 'name=stdin') {
+		if (argv.length > 1) {
+			fatal('"stdin" cannot be used with ' +
+			    'subsequent specifications');
+		}
+
+		if (opts.group) {
+			fatal('"stdin" cannot be used as a dump ' +
+			    'specification on reports');
+		}
+
+		dumpsFromStdin(client, opts, cb);
+		return;
+	}
+
 	var deref = function (dump, field) {
 		var f = field.split('.'), rval = dump;
 
@@ -1212,9 +1276,11 @@ processCore = function (client, stat, base, dump, cb)
 	cmd += 'echo \'\t"type": "core",\' >> ' + json + '; ';
 	cmd += 'echo \'\t"properties": {}\' >> ' + json + '; ';
 	cmd += 'echo } >> ' + json + '; ';
-	cmd += 'mput -f ' + json + ' ' + base + '/info.json';
+	cmd += 'mput -f ' + json + ' ' + base + '/info.json ; ';
+	cmd += jobExecThoth(json);
 
 	job = { phases: [ { exec: cmd, type: 'storage-map' } ] };
+	jobSetThoth(job);
 
 	status('creating job to process ' + mod_path.basename(base));
 
@@ -1342,9 +1408,11 @@ var processCrash = function (client, stat, base, dump, cb)
 	cmd += 'echo \'\t"type": "crash",\' >> ' + json + '; ';
 	cmd += 'echo \'\t"properties": {}\' >> ' + json + '; ';
 	cmd += 'echo } >> ' + json + '; ';
-	cmd += 'mput -f ' + json + ' ' + base + '/info.json';
+	cmd += 'mput -f ' + json + ' ' + base + '/info.json ; ';
+	cmd += jobExecThoth(json);
 
 	job = { phases: [ { exec: cmd, type: 'storage-map' } ] };
+	jobSetThoth(job);
 
 	status('creating job to process ' + mod_path.basename(base));
 
@@ -1586,7 +1654,7 @@ handlers.ls = function (client, argv)
 		}
 	};
 
-	dumpsFromSpec(argv, { fields: obj }, function (dumps) {
+	dumpsFromSpec(client, argv, { fields: obj }, function (dumps) {
 		for (i = 0; i < dumps.length; i++) {
 			if (!dumps[i].time)
 				dumps[i].time = 0;
@@ -1651,7 +1719,7 @@ handlers.info = function (client, argv)
 	if (argv.length == 1 && argv[0].indexOf('=') == -1) {
 		infoGet(client, argv[0], output);
 	} else {
-		dumpsFromSpec(argv, {}, output);
+		dumpsFromSpec(client, argv, {}, output);
 	}
 }
 
@@ -1812,7 +1880,7 @@ handlers.debug = function (client, argv)
 	if (argv.length == 1 && argv[0].indexOf('=') == -1) {
 		infoGet(client, argv[0], debug);
 	} else {
-		dumpsFromSpec(argv, { fields: [ 'dump' ] }, debug);
+		dumpsFromSpec(client, argv, { fields: [ 'dump' ] }, debug);
 	}
 }
 
@@ -2304,7 +2372,8 @@ handlers.report = function (client, argv)
 		}
 	}
 
-	dumpsFromSpec(argv, { fields: fields, group: true }, function (dumps) {
+	dumpsFromSpec(client, argv,
+	    { fields: fields, group: true }, function (dumps) {
 		var i, j, output = {}, val;
 
 		if (fields.length == 0) {
@@ -2664,13 +2733,41 @@ var setAnalyzer = function (client, exec, cb, opts)
 	});
 }
 
+var analyzerIsDcmd = function (analyzer)
+{
+	/*
+	 * If our analyzer begins with "::" or "$" or contains within it an
+	 * mdb verb (namely, "/", "=" or "::"), we assume it to be an mdb
+	 * dcmd.
+	 */
+	return (analyzer.indexOf('::') != -1 || analyzer.indexOf('$') == 0 ||
+	    analyzer.indexOf('/') > 0 || analyzer.indexOf('=') > 0);
+}
+
 var runAnalyzer = function (client, keys, analyzer)
 {
-	var cmd = 'cat $THOTH_ASSET /assets/' + analyzer + ' | bash\n';
+	var cmd;
+	var dcmd = false;
+
+	if (analyzerIsDcmd(analyzer)) {
+		status('executing mdb dcmd "' + analyzer + '"');
+		cmd = 'echo $THOTH_NAME: `echo \'' + analyzer +
+		    '\' | mdb $THOTH_DUMP 2> /dev/null`';
+		dcmd = true;
+	} else {
+		if (analyzer.indexOf('/') != 0)
+			analyzer = thoth.analyzers + '/' + analyzer;
+
+		cmd = 'cat $THOTH_ASSET /assets/' + analyzer + ' | bash\n';
+	}
 
 	setAnalyzer(client, cmd, function (asset) {
 		var preflight = function (job) {
-			job.phases[0].assets = [ asset, analyzer ];
+			job.phases[0].assets = [ asset ];
+
+			if (!dcmd)
+				job.phases[0].assets.push(analyzer);
+
 			job.phases.push({ exec: 'cat', type: 'reduce' });
 			jobSetThoth(job);
 		};
@@ -2755,7 +2852,7 @@ handlers.set = function (client, argv, sysprop)
 	if (i < argv.length)
 		argv.pop();
 
-	dumpsFromSpec(argv, { fields: [ 'name' ] }, function (dumps) {
+	dumpsFromSpec(client, argv, { fields: [ 'name' ] }, function (dumps) {
 		for (dump in dumps)
 			keys.push([ dumps[dump].name, 'info.json' ].join('/'));
 
@@ -2780,7 +2877,7 @@ handlers.unset = function (client, argv, sysprop)
 		return;
 	}
 
-	dumpsFromSpec(argv, { fields: [ 'name' ] }, function (dumps) {
+	dumpsFromSpec(client, argv, { fields: [ 'name' ] }, function (dumps) {
 		for (dump in dumps)
 			keys.push([ dumps[dump].name, 'info.json' ].join('/'));
 
@@ -2825,6 +2922,9 @@ handlers.analyzer = function (client, argv)
 	if (argv.length != 1)
 		fatal('analyzers must be named');
 
+	if (analyzerIsDcmd(argv[0]))
+		fatal('analyzer name may not contain mdb verbs or commands');
+
 	analyzer = thoth.analyzers + '/' + argv[0];
 	msg = 'analyzer \'' + argv[0] + '\'';
 
@@ -2936,9 +3036,6 @@ handlers.analyze = function (client, argv)
 	if (!analyzer)
 		fatal('need to specify an analyzer');
 
-	if (analyzer.indexOf('/') != 0)
-		analyzer = thoth.analyzers + '/' + analyzer;
-
 	if (argv.length == 1 && argv[0].indexOf('=') == -1) {
 		infoGet(client, argv[0], function (output) {
 			runAnalyzer(client, [ output.dump ], analyzer);
@@ -2947,7 +3044,7 @@ handlers.analyze = function (client, argv)
 		return;
 	}
 
-	dumpsFromSpec(argv, { fields: [ 'dump' ] }, function (dumps) {
+	dumpsFromSpec(client, argv, { fields: [ 'dump' ] }, function (dumps) {
 		var dump, keys = [];
 
 		for (dump in dumps)
diff --git a/package.json b/package.json
index 2bfff14..f9b1f36 100644
--- a/package.json
+++ b/package.json
@@ -1,7 +1,7 @@
 {
 	"name": "manta-thoth",
 	"description": "Manta-based system for core and crash dump analysis",
-	"version": "1.1.0",
+	"version": "1.2.0",
         "license": "MIT",
 	"author": "Joyent (joyent.com)",
 	"dependencies": {
-- 
2.21.0

